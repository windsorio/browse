# Pass `--web` to browse when running this example
# $ browse --web ./examples/thegazette.browse

# This is a long running script that keeps populating files in a ./notices
# directory with information extracted from notices on the London Gazette. Hit
# Ctrl+C to stop it after some time. This script probably won't end for a while

page https://www.thegazette.co.uk/all-notices/notice {
  print $url

  crawl `div.feed-item h3.title a`
  crawl `li.next a`
}

page https://www.thegazette.co.uk/notice/:issue {
  print $url
  pageConfig { set output "./notices/" + $issue + ".json" }

  wait `.wrapperContent`
  @string title `h1.title`
  @string? date `dd time`
  @string? notice `div[about="this:notifiableThing"]`

  out title date notice
}

visit https://www.thegazette.co.uk/all-notices/notice?text=&categorycode-all=all&noticetypes=&location-postcode-1=&location-distance-1=1&location-local-authority-1=&numberOfLocationSearches=1&start-publish-date=01%2F01%2F2000&end-publish-date=12%2F08%2F2020&edition=&london-issue=&edinburgh-issue=&belfast-issue=&sort-by=&results-page-size=10

# Also fetch these
for { set i 2; test $i < 5; set i $i + 1 } {
  visit https://www.thegazette.co.uk/London/issue/ + $i + "/page/2"
}
